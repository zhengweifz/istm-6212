{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook uses linux commands. Please run the cells using a linux system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - Word counts\n",
    "## Part A. Characters in Little Women\n",
    "### How many times are each of the following characters mentioned by name in the text of Little Women?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-21 12:45:32--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/women.txt\n",
      "Resolving raw.githubusercontent.com... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1053440 (1.0M) [text/plain]\n",
      "Saving to: ‘women.txt.3’\n",
      "\n",
      "women.txt.3         100%[===================>]   1.00M   673KB/s    in 1.5s    \n",
      "\n",
      "2016-09-21 12:45:34 (673 KB/s) - ‘women.txt.3’ saved [1053440/1053440]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/women.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   7 AMY\r\n",
      " 645 Amy\r\n",
      "   8 BETH\r\n",
      " 459 Beth\r\n",
      "   7 JO\r\n",
      "1355 Jo\r\n",
      "   3 MEG\r\n",
      " 683 Meg\r\n"
     ]
    }
   ],
   "source": [
    "!grep -oiE '\\bJo\\b|\\bBeth\\b|\\bMeg\\b|\\bAmy\\b' women.txt | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'\\b' in the above regular expression indicate word boundary. '-i' opiton for grep make it case insensitive. The counts are 645, 459, 1355, and 683 for Amy, Beth, Jo and Meg, respectively. But they do not include the counts for uppercase names, such as AMY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B. Juliet and Romeo in Romeo and Juliet\n",
    "### How many times do each of the characters Juliet and Romeo have speaking lines in Romeo and Juliet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-21 12:45:37--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/romeo.txt\n",
      "Resolving raw.githubusercontent.com... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 178983 (175K) [text/plain]\n",
      "Saving to: ‘romeo.txt.2’\n",
      "\n",
      "romeo.txt.2         100%[===================>] 174.79K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2016-09-21 12:45:37 (1.57 MB/s) - ‘romeo.txt.2’ saved [178983/178983]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/romeo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 117 Jul.\r\n",
      " 163 Rom.\r\n"
     ]
    }
   ],
   "source": [
    "!grep -oE \"Jul\\.|Rom\\.\" romeo.txt | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Jul.\" and  \"Rom.\" indicate speaking lines.\n",
    "There are 117 and 163 speaking lines for Juliet and Romeo, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Capital Bikeshare\n",
    "## Part A\n",
    "### Which 10 Capital Bikeshare stations were the most popular departing stations in Q1 2016?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-21 12:46:05--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/2016q1.csv.zip\n",
      "Resolving raw.githubusercontent.com... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10643003 (10M) [application/octet-stream]\n",
      "Saving to: ‘2016q1.csv.zip’\n",
      "\n",
      "2016q1.csv.zip      100%[===================>]  10.15M  1.63MB/s    in 7.5s    \n",
      "\n",
      "2016-09-21 12:46:13 (1.35 MB/s) - ‘2016q1.csv.zip’ saved [10643003/10643003]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/2016q1.csv.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"-o\" option for unzip overwrites the files if exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  2016q1.csv.zip\n",
      "  inflating: 2016q1.csv              \n"
     ]
    }
   ],
   "source": [
    "!unzip -o 2016q1.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1: Duration (ms)\r\n",
      "  2: Start date\r\n",
      "  3: End date\r\n",
      "  4: Start station number\r\n",
      "  5: Start station\r\n",
      "  6: End station number\r\n",
      "  7: End station\r\n",
      "  8: Bike number\r\n",
      "  9: Member Type\r\n"
     ]
    }
   ],
   "source": [
    "!csvcut -n 2016q1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|----------------+-----------------+---------------+----------------------+--------------------------------+--------------------+---------------------------+-------------+--------------|\r\n",
      "|  Duration (ms) | Start date      | End date      | Start station number | Start station                  | End station number | End station               | Bike number | Member Type  |\r\n",
      "|----------------+-----------------+---------------+----------------------+--------------------------------+--------------------+---------------------------+-------------+--------------|\r\n",
      "|  301295        | 3/31/2016 23:59 | 4/1/2016 0:04 | 31280                | 11th & S St NW                 | 31506              | 1st & Rhode Island Ave NW | W00022      | Registered   |\r\n",
      "|  557887        | 3/31/2016 23:59 | 4/1/2016 0:08 | 31275                | New Hampshire Ave & 24th St NW | 31114              | 18th St & Wyoming Ave NW  | W01294      | Registered   |\r\n",
      "|  555944        | 3/31/2016 23:59 | 4/1/2016 0:08 | 31101                | 14th & V St NW                 | 31221              | 18th & M St NW            | W01416      | Registered   |\r\n",
      "|  766916        | 3/31/2016 23:57 | 4/1/2016 0:09 | 31226                | 34th St & Wisconsin Ave NW     | 31214              | 17th & Corcoran St NW     | W01090      | Registered   |\r\n",
      "|----------------+-----------------+---------------+----------------------+--------------------------------+--------------------+---------------------------+-------------+--------------|\r\n"
     ]
    }
   ],
   "source": [
    "!csvcut 2016q1.csv | head -5 | csvlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below commands select \"start station\", the fifth column, sort the values of the column before using \"uniq -c\" to count unique values, then sort the unique values by count in a reverse order and print out the top 10 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13120 Columbus Circle / Union Station\r\n",
      "9560 Massachusetts Ave & Dupont Circle NW\r\n",
      "9388 Lincoln Memorial\r\n",
      "8138 Jefferson Dr & 14th St SW\r\n",
      "7479 Thomas Circle\r\n",
      "7401 15th & P St NW\r\n",
      "6568 14th & V St NW\r\n",
      "6491 New Hampshire Ave & T St NW\r\n",
      "5649 Eastern Market Metro / Pennsylvania Ave & 7th St SE\r\n",
      "5514 17th & Corcoran St NW\r\n"
     ]
    }
   ],
   "source": [
    "!csvcut -c5 2016q1.csv | sort | uniq -c | sort -rn | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Which 10 were the most popular destination stations in Q1 2016?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same logic for starting station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13880 Columbus Circle / Union Station\r\n",
      "11183 Massachusetts Ave & Dupont Circle NW\r\n",
      "9419 Lincoln Memorial\r\n",
      "8975 Jefferson Dr & 14th St SW\r\n",
      "8092 15th & P St NW\r\n",
      "7267 14th & V St NW\r\n",
      "6997 Thomas Circle\r\n",
      "6245 New Hampshire Ave & T St NW\r\n",
      "5761 5th & K St NW\r\n",
      "5651 17th & Corcoran St NW\r\n"
     ]
    }
   ],
   "source": [
    "!csvcut -c7 2016q1.csv | sort | uniq -c | sort -rn | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "### For the most popular departure station, which 10 bikes were used most in trips departing from there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  17 W22227\r\n",
      "  16 W21867\r\n",
      "  16 W21641\r\n",
      "  16 W21538\r\n",
      "  16 W21239\r\n",
      "  16 W20540\r\n",
      "  16 W00714\r\n",
      "  15 W22080\r\n",
      "  15 W21450\r\n",
      "  15 W21076\r\n"
     ]
    }
   ],
   "source": [
    "#filter the starting station for \"Columbus Circle / Union Station\", then find out which 10 bikes were used most.\n",
    "!csvgrep -c5 -m \"Columbus Circle / Union Station\" 2016q1.csv | csvcut -c8 | sort | uniq -c | sort -rn | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which 10 bikes were used most in trips ending at the most popular destination station?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  18 W00485\r\n",
      "  17 W22227\r\n",
      "  16 W22099\r\n",
      "  16 W22080\r\n",
      "  16 W21239\r\n",
      "  16 W21076\r\n",
      "  16 W20425\r\n",
      "  16 W00714\r\n",
      "  15 W21997\r\n",
      "  15 W21867\r\n"
     ]
    }
   ],
   "source": [
    "!csvgrep -c7 -m \"Columbus Circle / Union Station\" 2016q1.csv | csvcut -c8 | sort | uniq -c | sort -rn | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 - Filters\n",
    "## Part A\n",
    "## ! The .py files are written in Python 3 syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8155 and\r\n",
      "7689 the\r\n",
      "5152 to\r\n",
      "3523 of\r\n",
      "3245 her\r\n",
      "2774 it\r\n",
      "2503 in\r\n",
      "2447 you\r\n",
      "2343 she\r\n",
      "2233 for\r\n",
      "sort: write failed: standard output: Broken pipe\r\n",
      "sort: write error\r\n"
     ]
    }
   ],
   "source": [
    "!grep -oE '\\w{{2,}}' women.txt | tr '[:upper:]' '[:lower:]' | sort | uniq -c | sort -rn | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save user python path\n",
    "%sc my_python=which python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting grep_word.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile grep_word.py\n",
    "\n",
    "import fileinput\n",
    "import re\n",
    "\"\"\"\n",
    "A word splitter \n",
    "\"\"\"\n",
    "for line in fileinput.input():\n",
    "    for word in re.findall(r'\\w{2,}', line):\n",
    "        print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add shebang line\n",
    "!echo \"#!{my_python}`cat grep_word.py`\" > grep_word.py\n",
    "!chmod +x grep_word.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lower.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lower.py\n",
    "\n",
    "import fileinput\n",
    "\n",
    "\"\"\"\n",
    "Convert words into lowercase\n",
    "\"\"\"\n",
    "for line in fileinput.input():\n",
    "        #remove line break\n",
    "        line = line[:-1]\n",
    "        print(line.lower())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add shebang line\n",
    "!echo \"#!{my_python}`cat lower.py`\" > lower.py\n",
    "!chmod +x lower.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8155 and\r\n",
      "7689 the\r\n",
      "5152 to\r\n",
      "3523 of\r\n",
      "3245 her\r\n",
      "2774 it\r\n",
      "2503 in\r\n",
      "2447 you\r\n",
      "2343 she\r\n",
      "2233 for\r\n",
      "sort: write failed: standard output: Broken pipe\r\n",
      "sort: write error\r\n"
     ]
    }
   ],
   "source": [
    "!./grep_word.py women.txt | ./lower.py | sort | uniq -c | sort -rn | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-21 12:48:33--  http://xpo6.com/wp-content/uploads/2015/01/stop-word-list.csv\n",
      "Resolving xpo6.com... 104.28.21.102, 104.28.20.102, 2400:cb00:2048:1::681c:1466, ...\n",
      "Connecting to xpo6.com|104.28.21.102|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 669 [text/csv]\n",
      "Saving to: ‘stop-word-list.csv.1’\n",
      "\n",
      "stop-word-list.csv. 100%[===================>]     669  --.-KB/s    in 0s      \n",
      "\n",
      "2016-09-21 12:48:33 (37.5 MB/s) - ‘stop-word-list.csv.1’ saved [669/669]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Download a stop-word list\n",
    "!wget http://xpo6.com/wp-content/uploads/2015/01/stop-word-list.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'able', 'about', 'across', 'after', 'all', 'almost', 'also', 'am', 'among', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'because', 'been', 'but', 'by', 'can', 'cannot', 'could', 'dear', 'did', 'do', 'does', 'either', 'else', 'ever', 'every', 'for', 'from', 'get', 'got', 'had', 'has', 'have', 'he', 'her', 'hers', 'him', 'his', 'how', 'however', 'i', 'if', 'in', 'into', 'is', 'it', 'its', 'just', 'least', 'let', 'like', 'likely', 'may', 'me', 'might', 'most', 'must', 'my', 'neither', 'no', 'nor', 'not', 'of', 'off', 'often', 'on', 'only', 'or', 'other', 'our', 'own', 'rather', 'said', 'say', 'says', 'she', 'should', 'since', 'so', 'some', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'these', 'they', 'this', 'tis', 'to', 'too', 'twas', 'us', 'wants', 'was', 'we', 'were', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'would', 'yet', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "#read the csv to a list then print out\n",
    "with open(\"stop-word-list.csv\",'r') as f:\n",
    "    #it has only one line\n",
    "    stop_words = [word.strip() for word in f.read().strip().split(',')]\n",
    "    print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy it into the below filter function so what we do not read the csv everytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting remove_stop_word.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile remove_stop_word.py\n",
    "\n",
    "import fileinput\n",
    "\n",
    "\"\"\"\n",
    "A Filter For Removing Stop Words\n",
    "\"\"\"\n",
    "\n",
    "STOP_WORDS = ['a', 'able', 'about', 'across', 'after', 'all', 'almost', 'also', 'am', 'among', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'because', 'been', 'but', 'by', 'can', 'cannot', 'could', 'dear', 'did', 'do', 'does', 'either', 'else', 'ever', 'every', 'for', 'from', 'get', 'got', 'had', 'has', 'have', 'he', 'her', 'hers', 'him', 'his', 'how', 'however', 'i', 'if', 'in', 'into', 'is', 'it', 'its', 'just', 'least', 'let', 'like', 'likely', 'may', 'me', 'might', 'most', 'must', 'my', 'neither', 'no', 'nor', 'not', 'of', 'off', 'often', 'on', 'only', 'or', 'other', 'our', 'own', 'rather', 'said', 'say', 'says', 'she', 'should', 'since', 'so', 'some', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'these', 'they', 'this', 'tis', 'to', 'too', 'twas', 'us', 'wants', 'was', 'we', 'were', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'would', 'yet', 'you', 'your']\n",
    "\n",
    "for word in fileinput.input():\n",
    "    w = word.strip()\n",
    "    if w not in STOP_WORDS:\n",
    "        print(w)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add shebang line\n",
    "!echo \"#!{my_python}`cat remove_stop_word.py`\" > remove_stop_word.py\n",
    "!chmod +x remove_stop_word.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1362 jo\r\n",
      " 730 little\r\n",
      " 725 one\r\n",
      " 686 meg\r\n",
      " 658 up\r\n",
      " 652 amy\r\n",
      " 598 laurie\r\n",
      " 550 don\r\n",
      " 492 very\r\n",
      " 485 out\r\n",
      " 467 beth\r\n",
      " 462 good\r\n",
      " 399 now\r\n",
      " 393 go\r\n",
      " 380 old\r\n",
      " 377 mother\r\n",
      " 375 never\r\n",
      " 374 much\r\n",
      " 368 well\r\n",
      " 361 ll\r\n",
      " 360 see\r\n",
      " 355 over\r\n",
      " 346 more\r\n",
      " 331 away\r\n",
      " 321 time\r\n",
      "sort: write failed: standard output: Broken pipe\r\n",
      "sort: write error\r\n"
     ]
    }
   ],
   "source": [
    "!./grep_word.py women.txt | ./lower.py | ./remove_stop_word.py | sort | uniq -c | sort -rn | head -25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-09-21 12:49:21--  https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/texts.zip\n",
      "Resolving raw.githubusercontent.com... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12668137 (12M) [application/octet-stream]\n",
      "Saving to: ‘texts.zip’\n",
      "\n",
      "texts.zip           100%[===================>]  12.08M  1.76MB/s    in 8.4s    \n",
      "\n",
      "2016-09-21 12:49:29 (1.44 MB/s) - ‘texts.zip’ saved [12668137/12668137]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/gwsb-istm-6212-fall-2016/syllabus-and-schedule/master/projects/project-01/texts.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  texts.zip\n",
      "  inflating: ./text/10001.txt        \n",
      "  inflating: ./text/10002.txt        \n",
      "  inflating: ./text/10003.txt        \n",
      "  inflating: ./text/10004.txt        \n",
      "  inflating: ./text/10005.txt        \n",
      "  inflating: ./text/10006.txt        \n",
      "  inflating: ./text/10007.txt        \n",
      "  inflating: ./text/10008.txt        \n",
      "  inflating: ./text/10009.txt        \n",
      "  inflating: ./text/10010.txt        \n",
      "  inflating: ./text/10011.txt        \n",
      "  inflating: ./text/10012.txt        \n",
      "  inflating: ./text/10013.txt        \n",
      "  inflating: ./text/10014.txt        \n",
      "  inflating: ./text/10015.txt        \n",
      "  inflating: ./text/10016.txt        \n",
      "  inflating: ./text/10017.txt        \n",
      "  inflating: ./text/10018.txt        \n",
      "  inflating: ./text/10019.txt        \n",
      "  inflating: ./text/10020.txt        \n",
      "  inflating: ./text/10021.txt        \n",
      "  inflating: ./text/10023.txt        \n",
      "  inflating: ./text/10024.txt        \n",
      "  inflating: ./text/10025.txt        \n",
      "  inflating: ./text/10026.txt        \n",
      "  inflating: ./text/10027.txt        \n",
      "  inflating: ./text/10028.txt        \n",
      "  inflating: ./text/10029.txt        \n",
      "  inflating: ./text/10030.txt        \n",
      "  inflating: ./text/10031.txt        \n",
      "  inflating: ./text/10032.txt        \n",
      "  inflating: ./text/10033.txt        \n",
      "  inflating: ./text/10034.txt        \n",
      "  inflating: ./text/10035.txt        \n",
      "  inflating: ./text/10036.txt        \n",
      "  inflating: ./text/10037.txt        \n",
      "  inflating: ./text/10038.txt        \n",
      "  inflating: ./text/10039.txt        \n",
      "  inflating: ./text/10040.txt        \n",
      "  inflating: ./text/10041.txt        \n",
      "  inflating: ./text/10042.txt        \n",
      "  inflating: ./text/10043.txt        \n",
      "  inflating: ./text/10045.txt        \n",
      "  inflating: ./text/10046.txt        \n",
      "  inflating: ./text/10047.txt        \n",
      "  inflating: ./text/10048.txt        \n",
      "  inflating: ./text/10049.txt        \n",
      "  inflating: ./text/10050.txt        \n",
      "  inflating: ./text/10051.txt        \n",
      "  inflating: ./text/10052.txt        \n",
      "  inflating: ./text/10056.txt        \n",
      "  inflating: ./text/10059.txt        \n",
      "  inflating: ./text/10060.txt        \n",
      "  inflating: ./text/10062.txt        \n",
      "  inflating: ./text/12370.txt        \n",
      "  inflating: ./text/12372.txt        \n",
      "  inflating: ./text/12373.txt        \n",
      "  inflating: ./text/12374.txt        \n",
      "  inflating: ./text/12375.txt        \n",
      "  inflating: ./text/12376.txt        \n",
      "  inflating: ./text/12377.txt        \n",
      "  inflating: ./text/12378.txt        \n",
      "  inflating: ./text/12380.txt        \n",
      "  inflating: ./text/12381.txt        \n",
      "  inflating: ./text/12383.txt        \n",
      "  inflating: ./text/12384.txt        \n",
      "  inflating: ./text/12385.txt        \n",
      "  inflating: ./text/12386.txt        \n",
      "  inflating: ./text/1jcfs10.txt      \n",
      "  inflating: ./text/2babb10.txt      \n",
      "  inflating: ./text/3babb10.txt      \n",
      "  inflating: ./text/50bab10.txt      \n",
      "  inflating: ./text/ajtl10.txt       \n",
      "  inflating: ./text/allyr10.txt      \n",
      "  inflating: ./text/alpsn10.txt      \n",
      "  inflating: ./text/balen10.txt      \n",
      "  inflating: ./text/baleng2.txt      \n",
      "  inflating: ./text/batlf10.txt      \n",
      "  inflating: ./text/bgopr10.txt      \n",
      "  inflating: ./text/brnte10.txt      \n",
      "  inflating: ./text/bstjg10.txt      \n",
      "  inflating: ./text/cambp10.txt      \n",
      "  inflating: ./text/canbe10.txt      \n",
      "  inflating: ./text/cantp10.txt      \n",
      "  inflating: ./text/cfrz10.txt       \n",
      "  inflating: ./text/crsnk10.txt      \n",
      "  inflating: ./text/esbio10.txt      \n",
      "  inflating: ./text/grybr10.txt      \n",
      "  inflating: ./text/mklmt10.txt      \n",
      "  inflating: ./text/morem10.txt      \n",
      "  inflating: ./text/mspcd10.txt      \n",
      "  inflating: ./text/penbr10.txt      \n",
      "  inflating: ./text/pgjr10.txt       \n",
      "  inflating: ./text/pntvw10.txt      \n",
      "  inflating: ./text/prcpg10.txt      \n",
      "  inflating: ./text/prhg10.txt       \n",
      "  inflating: ./text/prhsb10.txt      \n",
      "  inflating: ./text/rlsl110.txt      \n",
      "  inflating: ./text/rlsl210.txt      \n",
      "  inflating: ./text/rmlav10.txt      \n",
      "  inflating: ./text/sesli10.txt      \n",
      "  inflating: ./text/svyrd10.txt      \n",
      "  inflating: ./text/tecom10.txt      \n",
      "  inflating: ./text/utrkj10.txt      \n",
      "  inflating: ./text/vpasm10.txt      \n",
      "  inflating: ./text/wldsp10.txt      \n",
      "  inflating: ./text/wtrbs10.txt      \n",
      "  inflating: ./text/zncli10.txt      \n"
     ]
    }
   ],
   "source": [
    "!unzip -o texts.zip -d ./text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all_words.txt if exists because the below parallel job uses '>>' to append to all_words.txt. We can get  wrong numbers if we run this notebook twice.  If all_words.txt does not exists,   '!rm all_words.txt' can generate an error, however, we can use '2>/dev/null', which redirects the error message to null, ignore this error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm all_words.txt 2>/dev/null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic tradition requires you to cite works you base your article on.\n",
      "When using programs that use GNU Parallel to process data for publication\n",
      "please cite:\n",
      "\n",
      "  O. Tange (2011): GNU Parallel - The Command-Line Power Tool,\n",
      "  ;login: The USENIX Magazine, February 2011:42-47.\n",
      "\n",
      "This helps funding further development; AND IT WON'T COST YOU A CENT.\n",
      "If you pay 10000 EUR you should feel free to use GNU Parallel without citing.\n",
      "\n",
      "To silence the citation notice: run 'parallel --citation'.\n",
      "\n",
      "\n",
      "Computers / CPU cores / Max jobs to run\n",
      "1:local / 8 / 8\n",
      "\n",
      "Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete\n",
      "ETA: 0s Left: 0 AVG: 0.07s  local:0/108/100%/0.1s \n",
      "\n",
      "real\t0m8.215s\n",
      "user\t0m55.024s\n",
      "sys\t0m2.897s\n"
     ]
    }
   ],
   "source": [
    "!time ls ./text/*.txt \\\n",
    "    | parallel --eta -j+0 \"grep -oE '\\w{{2,}}' {{}} | tr '[:upper:]' '[:lower:]' | ./remove_stop_word.py >> all_words.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19587 one\r\n",
      "12574 out\r\n",
      "12233 up\r\n",
      "10907 more\r\n",
      "9685 man\r\n",
      "9511 very\r\n",
      "9502 now\r\n",
      "8720 little\r\n",
      "8606 time\r\n",
      "8540 upon\r\n",
      "7765 gutenberg\r\n",
      "7489 see\r\n",
      "7323 well\r\n",
      "7264 project\r\n",
      "7102 over\r\n",
      "7018 such\r\n",
      "7015 two\r\n",
      "6891 down\r\n",
      "6822 great\r\n",
      "6781 old\r\n",
      "6749 day\r\n",
      "6670 work\r\n",
      "6670 know\r\n",
      "6566 good\r\n",
      "6446 made\r\n",
      "sort: write failed: standard output: Broken pipe\r\n",
      "sort: write error\r\n",
      "\r\n",
      "real\t0m56.100s\r\n",
      "user\t0m58.243s\r\n",
      "sys\t0m0.190s\r\n"
     ]
    }
   ],
   "source": [
    "!time ./grep_word.py all_words.txt | sort | uniq -c | sort -rn | head -25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
